{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Introduction to Data Analytics - Exercise set 5 - data processing and management</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your exercises (Jupyter Notebooks or Python-files) in your course Git-project.\n",
    "Use either code comments or Jupyter Notebook markdown (text) to document which exercise you are doing and what a certain code section does! \n",
    "You can return all of these exercises in a single Jupyter Notebook, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: red;\"><b>NOTE: The JSON/XML –files in Moodle in these exercises have been randomly generated. In other words, the data doesn't make any sense!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can import numpy and pandas here etc.\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>1. </b>Download <b>\"simple.json\"</b> in Moodle, and load it in pandas.</b> </h4>\n",
    "<p>\n",
    "The DataFrame should look like this:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex51.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>acquired</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chrysler</td>\n",
       "      <td>Voyager</td>\n",
       "      <td>2001</td>\n",
       "      <td>Wolff-Trantow</td>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>11565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Jetta</td>\n",
       "      <td>1995</td>\n",
       "      <td>Schuppe, Pfeffer and Klein</td>\n",
       "      <td>20/4/2016</td>\n",
       "      <td>52431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Cayenne</td>\n",
       "      <td>2005</td>\n",
       "      <td>Mante Group</td>\n",
       "      <td>11/6/2020</td>\n",
       "      <td>75552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>928</td>\n",
       "      <td>1994</td>\n",
       "      <td>Wisozk Group</td>\n",
       "      <td>17/6/2019</td>\n",
       "      <td>30331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL-Class</td>\n",
       "      <td>2007</td>\n",
       "      <td>Schiller-Littel</td>\n",
       "      <td>20/7/2018</td>\n",
       "      <td>62385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>Ram 1500 Club</td>\n",
       "      <td>2000</td>\n",
       "      <td>Schneider-Donnelly</td>\n",
       "      <td>28/9/2016</td>\n",
       "      <td>56256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>GMC</td>\n",
       "      <td>Yukon XL 2500</td>\n",
       "      <td>2001</td>\n",
       "      <td>Powlowski, Lemke and Wiza</td>\n",
       "      <td>19/4/2016</td>\n",
       "      <td>50163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Sportvan G20</td>\n",
       "      <td>1992</td>\n",
       "      <td>O'Keefe, Rogahn and Gleichner</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>8577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>3000GT</td>\n",
       "      <td>1993</td>\n",
       "      <td>Hoppe-Kunde</td>\n",
       "      <td>29/12/2018</td>\n",
       "      <td>23180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>TrailBlazer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Wunsch-Friesen</td>\n",
       "      <td>14/11/2018</td>\n",
       "      <td>76830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          brand          model  year                       owned_by  \\\n",
       "0     1       Chrysler        Voyager  2001                  Wolff-Trantow   \n",
       "1     2     Volkswagen          Jetta  1995     Schuppe, Pfeffer and Klein   \n",
       "2     3        Porsche        Cayenne  2005                    Mante Group   \n",
       "3     4        Porsche            928  1994                   Wisozk Group   \n",
       "4     5  Mercedes-Benz       SL-Class  2007                Schiller-Littel   \n",
       "..  ...            ...            ...   ...                            ...   \n",
       "95   96          Dodge  Ram 1500 Club  2000             Schneider-Donnelly   \n",
       "96   97            GMC  Yukon XL 2500  2001      Powlowski, Lemke and Wiza   \n",
       "97   98      Chevrolet   Sportvan G20  1992  O'Keefe, Rogahn and Gleichner   \n",
       "98   99     Mitsubishi         3000GT  1993                    Hoppe-Kunde   \n",
       "99  100      Chevrolet    TrailBlazer  2002                 Wunsch-Friesen   \n",
       "\n",
       "      acquired  price  \n",
       "0   28/12/2016  11565  \n",
       "1    20/4/2016  52431  \n",
       "2    11/6/2020  75552  \n",
       "3    17/6/2019  30331  \n",
       "4    20/7/2018  62385  \n",
       "..         ...    ...  \n",
       "95   28/9/2016  56256  \n",
       "96   19/4/2016  50163  \n",
       "97    1/6/2019   8577  \n",
       "98  29/12/2018  23180  \n",
       "99  14/11/2018  76830  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download, covert to df and open it\n",
    "df = pd.read_json(\"simple.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>2.</b> Download <b>\"simple.xml\"</b> in Moodle, and load it in pandas</h4>\n",
    "<p>\n",
    "<span style=\"color: red\"><b>Note:</b> pandas.read_xml() doesn't work well with this data.</span><br /><br >The Series should look something like this:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52cars.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>acquired</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oldsmobile</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2003</td>\n",
       "      <td>Herzog, Rodriguez and Howe</td>\n",
       "      <td>21/10/2016</td>\n",
       "      <td>32571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id       brand   model  year                    owned_by    acquired  price\n",
       "0  1  Oldsmobile  Aurora  2003  Herzog, Rodriguez and Howe  21/10/2016  32571"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load XML-file, and get root node\n",
    "xtree = et.parse(\"simple.xml\")\n",
    "node = xtree.getroot()\n",
    "\n",
    "# column names for pandas to create DataFrame later\n",
    "df_cols = [\"id\", \"brand\", \"model\", \"year\", \"owned_by\", \"acquired\", \"price\"]\n",
    "rows = []\n",
    "\n",
    "# parse values\n",
    "e_id = node.find(\"id\").text\n",
    "e_brand = node.find(\"brand\").text\n",
    "e_model = node.find(\"model\").text\n",
    "e_year = node.find(\"year\").text\n",
    "e_owned_by = node.find(\"owned_by\").text\n",
    "e_acquired = node.find(\"acquired\").text\n",
    "e_price = node.find(\"price\").text\n",
    "\n",
    "# create DataFrame\n",
    "rows.append({\"id\": e_id, \"brand\": e_brand, \"model\": e_model, \"year\": e_year, \"owned_by\": e_owned_by, \"acquired\": e_acquired, \"price\": e_price})\n",
    "out_df = pd.DataFrame(rows, columns = df_cols)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>3. Load this API-data into a pandas DataFrame:</b></h4>\n",
    "<p><a href=\"https://edu.frostbit.fi/api/events/en/\">https://edu.frostbit.fi/api/events/en/</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Remember to use json_normalize to help you out with the categories and address information.<br /><b>Have address information in their own columns, and categories as separate rows.</b><br />The DataFrame should look something like this (note that the data changes daily, and exact values will vary):\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53events.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>4. Use web scraping (e.g. BeautifulSoup), and use it to get the following info from the Rovaniemi Wikipedia –page</b></h4>\n",
    "<p><b>Wiki-page:</b> <a href=\"https://en.wikipedia.org/wiki/Rovaniemi\">https://en.wikipedia.org/wiki/Rovaniemi</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tasks:</b>\n",
    "<ul>\n",
    "    <li>Get the coordinates of Rovaniemi (upper right corner)</li>\n",
    "    <li>Get the nickname of Rovaniemi (under coat of arms)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra tasks:</b>\n",
    "<ul>\n",
    "    <li><b>Get the total population</b></li>\n",
    "    <ul>\n",
    "        <li><b>Note:</b> this is a good example why webscraping can be tedious, since you'll have to traverse the HTML-tree to get what you want. This might be helpful:<br />\n",
    "<a href=\"https://realpython.com/beautiful-soup-web-scraper-python/\">https://realpython.com/beautiful-soup-web-scraper-python/</a></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Get the total area</b></li>\n",
    "    <ul>\n",
    "        <li>Convert this number into a float decimal (i.e. remove commas and the unit and call float() –in Python!)</li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex54rovaniemi.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>5. Use web scraping, and create a DataFrame of this table: </b></h4>\n",
    "<p> <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature\">https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Change the name of the value column to \"avg_temp\" as well (pandas column rename)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra task:</b>\n",
    "<ul>\n",
    "    <li><b>Scrape these two tables as well</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate</a></li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate</a></li>\n",
    "    </ul>\n",
    "    <br />\n",
    "    <ul>\n",
    "        <li><b>Combine the tables into a single DataFrame so that you get only the data of year 2020 or newer, and have the columns <span style=\"color: darkorange\">\"Country\", \"EmploymentRate\"</span> and <span style=\"color: darkorange\">\"UnemploymentRate\"</span>. You can also create additional columns <span style=\"color: indigo\">\"EmploymentRate15_24\"</span>and <span style=\"color: indigo\">\" EmploymentRate25_70\"</span> if you scrape the OECD-table as well! </b>\n",
    "\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex55stocks.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>Advanced extra tasks for extra points (varying challenges, some require Googling):</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>1. Download the \"complex.json\" –file from Moodle.</b> Note that this data is fairly complex (i.e. heavily nested). Use json_normalize and other needed methods to convert this data into a workable DataFrame.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>2. Load the \"simple.json\" –file without pandas, and try to get the average price with plain Python. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3. Download the \"complex.xml\" file from Moodle, and create a DataFrame out of it.</b></li>\n",
    "<ul>\n",
    "    <li><b>Note:</b> using pandas.read_xml() would otherwise work, but it ignores the \"ownership\" –field. You'll have to find another way to get this data into your DataFrame as well!</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>4. Try out Selenium on a site that cannot be scraped with traditional methods. You can use this tutorial as the starting point:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.toptal.com/python/web-scraping-with-python\">https://www.toptal.com/python/web-scraping-with-python</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex5charts.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Extra challenging advanced task: <span style=\"color: red;\">integrating data sources</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Integrate two or more datasets into one matching dataset  (pandas DataFrame)</b></li>\n",
    "<ul>\n",
    "<li><b>For example:</b> see the integration case in our berry semester project!</li>\n",
    "</ul>\n",
    "<br />\n",
    "<ul>\n",
    "<li>Find two or more datasets (Kaggle etc.) that have something in common and can be used for merging. </li>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>Typical common columns:</b></li>\n",
    "<ul>\n",
    "<li>Coordinates (lat/lng etc.)</li>\n",
    "<li>Years, months</li>\n",
    "<li>reference ids (e.g. product id -> product data)</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>You can use pandas.merge() in order to combine DataFrames</b></li>\n",
    "<ul>\n",
    "<li>When combining DataFrames, make sure that the merge doesn’t mess up your data</li>\n",
    "<li><b>Note:</b> merge can often create way too many extra rows depending on the merging parameters</li>\n",
    "\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>This exercise can provide even large amounts of points, depending on difficulty. Aspects that affect grading:</b></li>\n",
    "<ul>\n",
    "<li>Amount of datasets</li>\n",
    "<li>Difficulty of the datasets</li>\n",
    "<li>Using different data formats all at once (XML, JSON, CSV etc.)</li>\n",
    "<li>Other techniques used to add data: web scraping, data APIs etc.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this exercise is probably better to do in a separate Jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b393597a1a01400f99fd0b0bd7e53e32f7c09a6c4e3f1d7dcfe73f5e3a50c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
