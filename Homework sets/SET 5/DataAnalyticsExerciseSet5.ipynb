{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Introduction to Data Analytics - Exercise set 5 - data processing and management</b></h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your exercises (Jupyter Notebooks or Python-files) in your course Git-project.\n",
    "Use either code comments or Jupyter Notebook markdown (text) to document which exercise you are doing and what a certain code section does! \n",
    "You can return all of these exercises in a single Jupyter Notebook, if you wish."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: red;\"><b>NOTE: The JSON/XML –files in Moodle in these exercises have been randomly generated. In other words, the data doesn't make any sense!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can import numpy and pandas here etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>1. </b>Download <b>\"simple.json\"</b> in Moodle, and load it in pandas.</b> </h4>\n",
    "<p>\n",
    "The DataFrame should look like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex51.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>2.</b> Download <b>\"simple.xml\"</b> in Moodle, and load it in pandas</h4>\n",
    "<p>\n",
    "<span style=\"color: red\"><b>Note:</b> pandas.read_xml() doesn't work well with this data.</span><br /><br >The Series should look something like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52cars.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>3. Load this API-data into a pandas DataFrame:</b></h4>\n",
    "<p><a href=\"https://edu.frostbit.fi/api/events/en/\">https://edu.frostbit.fi/api/events/en/</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Remember to use json_normalize to help you out with the categories and address information.<br /><b>Have address information in their own columns, and categories as separate rows.</b><br />The DataFrame should look something like this (note that the data changes daily, and exact values will vary):\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53events.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>4. Use web scraping (e.g. BeautifulSoup), and use it to get the following info from the Rovaniemi Wikipedia –page</b></h4>\n",
    "<p><b>Wiki-page:</b> <a href=\"https://en.wikipedia.org/wiki/Rovaniemi\">https://en.wikipedia.org/wiki/Rovaniemi</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tasks:</b>\n",
    "<ul>\n",
    "    <li>Get the coordinates of Rovaniemi (upper right corner)</li>\n",
    "    <li>Get the nickname of Rovaniemi (under coat of arms)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra tasks:</b>\n",
    "<ul>\n",
    "    <li><b>Get the total population</b></li>\n",
    "    <ul>\n",
    "        <li><b>Note:</b> this is a good example why webscraping can be tedious, since you'll have to traverse the HTML-tree to get what you want. This might be helpful:<br />\n",
    "<a href=\"https://realpython.com/beautiful-soup-web-scraper-python/\">https://realpython.com/beautiful-soup-web-scraper-python/</a></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Get the total area</b></li>\n",
    "    <ul>\n",
    "        <li>Convert this number into a float decimal (i.e. remove commas and the unit and call float() –in Python!)</li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex54rovaniemi.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>5. Use web scraping, and create a DataFrame of this table: </b></h4>\n",
    "<p> <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature\">https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Change the name of the value column to \"avg_temp\" as well (pandas column rename)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra task:</b>\n",
    "<ul>\n",
    "    <li><b>Scrape these two tables as well</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate</a></li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate</a></li>\n",
    "    </ul>\n",
    "    <br />\n",
    "    <ul>\n",
    "        <li><b>Combine the tables into a single DataFrame so that you get only the data of year 2020 or newer, and have the columns <span style=\"color: darkorange\">\"Country\", \"EmploymentRate\"</span> and <span style=\"color: darkorange\">\"UnemploymentRate\"</span>. You can also create additional columns <span style=\"color: indigo\">\"EmploymentRate15_24\"</span>and <span style=\"color: indigo\">\" EmploymentRate25_70\"</span> if you scrape the OECD-table as well! </b>\n",
    "\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex55stocks.jpg\" width=\"600\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>Advanced extra tasks for extra points (varying challenges, some require Googling):</b></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>1. Download the \"complex.json\" –file from Moodle.</b> Note that this data is fairly complex (i.e. heavily nested). Use json_normalize and other needed methods to convert this data into a workable DataFrame.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>2. Load the \"simple.json\" –file without pandas, and try to get the average price with plain Python. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3. Download the \"complex.xml\" file from Moodle, and create a DataFrame out of it.</b></li>\n",
    "<ul>\n",
    "    <li><b>Note:</b> using pandas.read_xml() would otherwise work, but it ignores the \"ownership\" –field. You'll have to find another way to get this data into your DataFrame as well!</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>4. Try out Selenium on a site that cannot be scraped with traditional methods. You can use this tutorial as the starting point:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.toptal.com/python/web-scraping-with-python\">https://www.toptal.com/python/web-scraping-with-python</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex5charts.jpg\" width=\"600\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Extra challenging advanced task: <span style=\"color: red;\">integrating data sources</span></b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Integrate two or more datasets into one matching dataset  (pandas DataFrame)</b></li>\n",
    "<ul>\n",
    "<li><b>For example:</b> see the integration case in our berry semester project!</li>\n",
    "</ul>\n",
    "<br />\n",
    "<ul>\n",
    "<li>Find two or more datasets (Kaggle etc.) that have something in common and can be used for merging. </li>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>Typical common columns:</b></li>\n",
    "<ul>\n",
    "<li>Coordinates (lat/lng etc.)</li>\n",
    "<li>Years, months</li>\n",
    "<li>reference ids (e.g. product id -> product data)</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>You can use pandas.merge() in order to combine DataFrames</b></li>\n",
    "<ul>\n",
    "<li>When combining DataFrames, make sure that the merge doesn’t mess up your data</li>\n",
    "<li><b>Note:</b> merge can often create way too many extra rows depending on the merging parameters</li>\n",
    "\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>This exercise can provide even large amounts of points, depending on difficulty. Aspects that affect grading:</b></li>\n",
    "<ul>\n",
    "<li>Amount of datasets</li>\n",
    "<li>Difficulty of the datasets</li>\n",
    "<li>Using different data formats all at once (XML, JSON, CSV etc.)</li>\n",
    "<li>Other techniques used to add data: web scraping, data APIs etc.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this exercise is probably better to do in a separate Jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b393597a1a01400f99fd0b0bd7e53e32f7c09a6c4e3f1d7dcfe73f5e3a50c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
